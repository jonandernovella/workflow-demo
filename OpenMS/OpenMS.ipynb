{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenMS Workflow\n",
    "OpenMS is an open source platform for LC/MS data pre-processing and analysis. \n",
    "Several tools have been developed using OpenMS library including noise reduction, centroiding, quantification, and alignment. \n",
    "\n",
    "The following workflow has been developed to perform a simple LC/MS metabolomics data processing and analysis using OpenMS, Python, and R, utilizing the Docker containers concept. All the Docker images are available through [DockerHub](https://hub.docker.com/r/payamemami/) and the Docker files can be obtained through the [PhenoMeNal GitHub](https://github.com/phnmnl/workflow-demo). \n",
    "\n",
    "A typical LC/MC data processing consists of the following components:\n",
    "- \n",
    "- Peak picking (centroiding)\n",
    "- Feature Finding (quantification)\n",
    "- Feature Linking (matching)\n",
    "- Conversion (e.g. to tab-separated values files)\n",
    "- Downstream Analysis\n",
    "\n",
    "In the rest of this text, we will go through all the mentioned steps using OpenMS. For more information about specific tools please refer to [OpenMS documentation](http://ftp.mi.fu-berlin.de/pub/OpenMS/release-documentation/html/index.html). We will also use iPython within Jupyter notebook as the interface and R for downstream data analysis.\n",
    "\n",
    "\n",
    "## Data prepration\n",
    "Assuming you are in the root directory of Jupyter, we create a folder (named \"OpenMS\") and change the working directory to this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "workingDir=\"OpenMS\"\n",
    "if not os.path.exists(workingDir):\n",
    "    os.makedirs(workingDir)\n",
    "os.chdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then download two text files (called \"data_list.txt\" and \"params.txt\") where \"data_list.txt\" contains the names of the raw MS files (mzML) and download links for each of the files.\n",
    "In addition, since OpenMS tools reads parameters as \".ini\" files, we also need to download these files from the links provided in \"params.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/PayamE/Containers/master/data/data_list.txt\",\"data_list.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/PayamE/Containers/master/data/params.txt\",\"params.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create two folders (\"rawFiles\" and \"paramFiles\") and download the files using the links provided in \"data_list.txt\" and \"params.txt\" to their corresponding folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "rawDirectory=\"rawFiles\"\n",
    "if not os.path.exists(rawDirectory):\n",
    "    os.makedirs(rawDirectory)\n",
    "paramDirectory=\"paramFiles\"\n",
    "if not os.path.exists(paramDirectory):\n",
    "    os.makedirs(paramDirectory)\n",
    "param_path=[]\n",
    "with open('params.txt','r') as f:\n",
    "    reader=csv.reader(f,delimiter='\\t')\n",
    "    for row in reader:\n",
    "        urllib.request.urlretrieve(row[1],paramDirectory+\"/\"+row[0])\n",
    "        param_path.append(row)\n",
    "        \n",
    "\n",
    "data_path=[]\n",
    "with open('data_list.txt','r') as f:\n",
    "    reader=csv.reader(f,delimiter='\\t')\n",
    "    for row in reader:\n",
    "        urllib.request.urlretrieve(row[1],rawDirectory+\"/\"+row[0])\n",
    "        data_path.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we suppress possible warnings which might be issued due to insecure connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning) # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We input the address to the control node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "control=input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as the password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "password=getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to perform the first step of data pre-processing!\n",
    "## Peak Picking and feature finding\n",
    "Here we begin with peak picking which converts raw data into peak lists which will be used for further processing. We will then perform feature finding on the centrioded data (resulted from peak picking) to detect retention time and isotope. \n",
    "\n",
    "\n",
    "Briefly, for each raw data file, we prepare two \"json\" files. The first json (\"json_peakpicker\") will be used to spin up \"PeakPickerHiRes\" Docker container on a raw mzML file and the second json \"(json_featurefinder\") will be used for performing feature finding using \"FeatureFinderMetabo\" container on the result of PeakPickerHiRes. The most important difference in spin up method between PeakPickerHiRes and FeatureFinderMetabo is that FeatureFinderMetabo will be a dependent job, meaning that it will only run if \"PeakPickerHiRes\" has  successfully finished. So, a FeatureFinderMetabo container, set to work on file \"X\", will run if PeakPickerHiRes on the same file (\"X\") has finished. This means that a large number of PeakPickerHiRes-FeatureFinderMetabo pairs can be run at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_peakPicker=\"https://admin:\"+password+\"@\"+control+\"/chronos/scheduler/iso8601\"\n",
    "url_featureFinder=\"https://admin:\"+password+\"@\"+control+\"/chronos/scheduler/dependency\"\n",
    "i=0\n",
    "containerNamesfeatureFinder=[]\n",
    "featureFinderoutNames=[]\n",
    "peakPickerDir=\"peakPickerDir\"\n",
    "featureFinderDir=\"featureFinderDir\"\n",
    "if not os.path.exists(peakPickerDir):\n",
    "    os.makedirs(peakPickerDir)\n",
    "if not os.path.exists(featureFinderDir):\n",
    "    os.makedirs(featureFinderDir)\n",
    "#2030-01-01T12:00:00Z\n",
    "for mzFile in data_path:\n",
    "    i=i+1\n",
    "    peakPickerInputFile=mzFile[0]\n",
    "    peakPickerOutputFile=mzFile[0]\n",
    "    containerNamePeakPicker=\"peakpickerhires\"+\"_\"+peakPickerInputFile.replace(\".mzML\",\"\")\n",
    "    json_peakpicker=\"\"\"\n",
    "    { \n",
    "        \"schedule\" : \"R1//PT1H\",  \n",
    "        \"cpus\": \"0.25\",\n",
    "        \"mem\": \"100\",  \n",
    "        \"epsilon\" : \"PT10M\",  \n",
    "        \"name\" : \"%s\",\n",
    "        \"container\": {\n",
    "            \"type\": \"DOCKER\",\n",
    "            \"image\": \"payamemami/peakpickerhires\",\n",
    "            \"volumes\": [{\n",
    "                \"hostPath\": \"/mnt/container-volumes/jupyter/%s\",\n",
    "                \"containerPath\": \"/data\",\n",
    "                \"mode\": \"RW\"\n",
    "             }]\n",
    "        },\n",
    "        \"command\" : \"PeakPickerHiRes -in /data/%s/%s -out /data/%s/%s -ini /data/%s\",\n",
    "        \"owner\" : \"payam.emami@medsci.uu.se\"\n",
    "    }\n",
    "    \"\"\" % (containerNamePeakPicker,workingDir,rawDirectory,peakPickerInputFile,peakPickerDir ,peakPickerOutputFile, paramDirectory+\"/peakPickerParam.ini\")\n",
    "    featureFinderoutput=peakPickerOutputFile.replace(\".mzML\",\".featureXML\")\n",
    "    containerNamefeatureFinder=\"featurefindermetabo\"+\"_\"+peakPickerOutputFile.replace(\".mzML\",\"\")\n",
    "    containerNamesfeatureFinder.append(containerNamefeatureFinder)\n",
    "    featureFinderoutNames.append(featureFinderoutput)\n",
    "    json_featurefinder=\"\"\"\n",
    "    { \n",
    "        \"parents\" : [\"%s\"],\n",
    "        \"cpus\": \"0.25\",\n",
    "        \"mem\": \"100\",  \n",
    "        \"epsilon\" : \"PT10M\",  \n",
    "        \"name\" : \"%s\",\n",
    "        \"container\": {\n",
    "            \"type\": \"DOCKER\",\n",
    "            \"image\": \"payamemami/featurefindermetabo\",\n",
    "            \"volumes\": [{\n",
    "                \"hostPath\": \"/mnt/container-volumes/jupyter/%s\",\n",
    "                \"containerPath\": \"/data\",\n",
    "                \"mode\": \"RW\"\n",
    "             }]\n",
    "        },STAGING\n",
    "        \"command\" : \"FeatureFinderMetabo -in /data/%s/%s -out /data/%s/%s -ini /data/%s\",\n",
    "        \"owner\" : \"payam.emami@medsci.uu.se\"\n",
    "    }\n",
    "    \"\"\" % (containerNamePeakPicker,containerNamefeatureFinder,workingDir,peakPickerDir,peakPickerOutputFile,featureFinderDir ,featureFinderoutput,paramDirectory+\"/featureFinderParam.ini\")\n",
    "\n",
    "    response=requests.post(url_peakPicker, headers = {'content-type' : 'application/json'}, data=json_peakpicker, verify=False)\n",
    "    print(\"HTTP response code peakPicker: \" + str(response.status_code))\n",
    "    response=requests.post(url_featureFinder, headers = {'content-type' : 'application/json'}, data=json_featurefinder, verify=False)\n",
    "    print(\"HTTP response code featureFinder: \" + str(response.status_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature linking\n",
    "This process is used to match corresponding features across all the MS runs.\n",
    "The method of spinning up is similar to that of feature finder. However, the container (\"featurelinkerunlabeledqt\") will be dependent on all of the FeatureFinderMetabo containers in the previous step. This means that \"featurelinkerunlabeledqt\" will only run if all the FeatureFinderMetabo processes successfully finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureLinkerDir=\"featureLinkerDir\"\n",
    "if not os.path.exists(featureLinkerDir):\n",
    "    os.makedirs(featureLinkerDir)\n",
    "url_featureLinker=\"https://admin:\"+password+\"@\"+control+\"/chronos/scheduler/dependency\"\n",
    "featureLinkerInput=' '.join([\"/data/\"+featureFinderDir+\"/\" + fileName for fileName in featureFinderoutNames])\n",
    "featureLinkerOutput=\"featureLinkerResult.consensusXML\"\n",
    "containerNamefeatureLinker=\"featureLinker\"\n",
    "parents=\"%s\"%(containerNamesfeatureFinder)\n",
    "json_featureLinker=\"\"\"\n",
    "    { \n",
    "        \"parents\" : %s,\n",
    "        \"cpus\": \"0.25\",\n",
    "        \"mem\": \"100\",  \n",
    "        \"epsilon\" : \"PT10M\",  \n",
    "        \"name\" : \"%s\",\n",
    "        \"container\": {\n",
    "            \"type\": \"DOCKER\",\n",
    "            \"image\": \"payamemami/featurelinkerunlabeledqt\",\n",
    "            \"volumes\": [{\n",
    "                \"hostPath\": \"/mnt/container-volumes/jupyter/%s\",\n",
    "                \"containerPath\": \"/data\",\n",
    "                \"mode\": \"RW\"\n",
    "             }]\n",
    "        },\n",
    "        \"command\" : \"FeatureLinkerUnlabeledQT -in %s -out /data/%s/%s -ini /data/%s\",\n",
    "        \"owner\" : \"payam.emami@medsci.uu.se\"\n",
    "    }\n",
    "    \"\"\" % (parents.replace(\"\\'\",\"\\\"\"),containerNamefeatureLinker,workingDir,featureLinkerInput,featureLinkerDir,featureLinkerOutput,paramDirectory+\"/featureLinkerParam.ini\")\n",
    "response=requests.post(url_featureLinker, headers = {'content-type' : 'application/json'}, data=json_featureLinker, verify=False)\n",
    "print(\"HTTP response code featureFinder: \" + str(response.status_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to CSV file\n",
    "The consensusXML output of the linking process will be converted to a CSV file. This process is also dependent on the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textExporterDir=\"textExporterDir\"\n",
    "if not os.path.exists(textExporterDir):\n",
    "    os.makedirs(textExporterDir)\n",
    "url_textExporter=\"https://admin:\"+password+\"@\"+control+\"/chronos/scheduler/dependency\"\n",
    "textExporterInput=featureLinkerDir+\"/\"+featureLinkerOutput\n",
    "textExporterOutput=\"textExporterOutput.csv\"\n",
    "containerNameTextExporter=\"textexporter\"\n",
    "parents=\"%s\"%(containerNamefeatureLinker)\n",
    "json_textExporter=\"\"\"\n",
    "    { \n",
    "        \"parents\" : [\"%s\"],\n",
    "        \"cpus\": \"0.25\",\n",
    "        \"mem\": \"100\",  \n",
    "        \"epsilon\" : \"PT10M\",  \n",
    "        \"name\" : \"%s\",\n",
    "        \"container\": {\n",
    "            \"type\": \"DOCKER\",\n",
    "            \"image\": \"payamemami/textexporter\",\n",
    "            \"volumes\": [{\n",
    "                \"hostPath\": \"/mnt/container-volumes/jupyter/%s\",\n",
    "                \"containerPath\": \"/data\",\n",
    "                \"mode\": \"RW\"\n",
    "             }]\n",
    "        },\n",
    "        \"command\" : \"TextExporter -in /data/%s -out /data/%s/%s -ini /data/%s\",\n",
    "        \"owner\" : \"payam.emami@medsci.uu.se\"\n",
    "    }\n",
    "    \"\"\" % (parents,containerNameTextExporter,workingDir,textExporterInput,textExporterDir,textExporterOutput,paramDirectory+\"/textExporter.ini\")\n",
    "response=requests.post(url_textExporter, headers = {'content-type' : 'application/json'}, data=json_textExporter, verify=False)\n",
    "print(\"HTTP response code featureFinder: \" + str(response.status_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the CSV file in R\n",
    "The CSV file from the previous step is converted to an \"Excel\" like file. This step will only run if TextExporter has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convertToDecyderDir=\"convertToDecyderDir\"\n",
    "if not os.path.exists(convertToDecyderDir):\n",
    "    os.makedirs(convertToDecyderDir)\n",
    "url_convertToDecyder=\"https://admin:\"+password+\"@\"+control+\"/chronos/scheduler/dependency\"\n",
    "convertToDecyderInput=textExporterDir+\"/\"+textExporterOutput\n",
    "convertToDecyderOutput=\"\"\n",
    "containerNameconvertToDecyder=\"converttodecyder\"\n",
    "textExporterOutputName=\"textExporterOutput.xls\"\n",
    "parents=\"%s\"%(containerNameTextExporter)\n",
    "json_textExporter=\"\"\"\n",
    "    { \n",
    "        \"parents\" : [\"%s\"],\n",
    "        \"cpus\": \"0.25\",\n",
    "        \"mem\": \"100\",  \n",
    "        \"epsilon\" : \"PT10M\",  \n",
    "        \"name\" : \"%s\",\n",
    "        \"container\": {\n",
    "            \"type\": \"DOCKER\",\n",
    "            \"image\": \"payamemami/converttodecyder\",\n",
    "            \"volumes\": [{\n",
    "                \"hostPath\": \"/mnt/container-volumes/jupyter/%s\",\n",
    "                \"containerPath\": \"/data\",\n",
    "                \"mode\": \"RW\"\n",
    "             }]\n",
    "        },\n",
    "        \"command\" : \"Rscript convert_to_decyder.R -in=/data/%s -out=/data/%s -name=%s\",\n",
    "        \"owner\" : \"payam.emami@medsci.uu.se\"\n",
    "    }\n",
    "    \"\"\" % (parents,containerNameconvertToDecyder,workingDir,convertToDecyderInput,convertToDecyderDir,textExporterOutputName)\n",
    "response=requests.post(url_textExporter, headers = {'content-type' : 'application/json'}, data=json_textExporter, verify=False)\n",
    "print(\"HTTP response code featureFinder: \" + str(response.status_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the formatted file, we plot the data using R functions from the ggplot package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotDir=\"plotDir\"\n",
    "if not os.path.exists(plotDir):\n",
    "    os.makedirs(plotDir)\n",
    "url_plot=\"https://admin:\"+password+\"@\"+control+\"/chronos/scheduler/dependency\"\n",
    "plotInput=convertToDecyderDir+\"/\"+textExporterOutputName\n",
    "plotOutput=\"plot.png\"\n",
    "containerNameplot=\"plotmsdata\"\n",
    "parents=\"%s\"%(containerNameconvertToDecyder)\n",
    "json_plot=\"\"\"\n",
    "    { \n",
    "        \"parents\" : [\"%s\"],\n",
    "        \"cpus\": \"0.25\",\n",
    "        \"mem\": \"100\",  \n",
    "        \"epsilon\" : \"PT10M\",  \n",
    "        \"name\" : \"%s\",\n",
    "        \"container\": {\n",
    "            \"type\": \"DOCKER\",\n",
    "            \"image\": \"payamemami/plotmsdata\",\n",
    "            \"volumes\": [{\n",
    "                \"hostPath\": \"/mnt/container-volumes/jupyter/%s\",\n",
    "                \"containerPath\": \"/data\",\n",
    "                \"mode\": \"RW\"\n",
    "             }]\n",
    "        },\n",
    "        \"command\" : \"Rscript plotMSData.R -in=/data/%s -out=/data/%s/%s -pattern=intensity_ -impute=T -plottype=BOX -width=20 -height=20 -imagetype=PNG -log=T\",\n",
    "        \"owner\" : \"payam.emami@medsci.uu.se\"\n",
    "    }\n",
    "    \"\"\" % (parents,containerNameplot,workingDir,plotInput,plotDir,plotOutput)\n",
    "response=requests.post(url_plotDir, headers = {'content-type' : 'application/json'}, data=json_plot, verify=False)\n",
    "print(\"HTTP response code featureFinder: \" + str(response.status_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can see the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=plotDir+\"/\"+plotOutput) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
